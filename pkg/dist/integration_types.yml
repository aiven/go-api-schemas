autoscaler:
  title: Integration user config
  type: object
clickhouse_credentials:
  title: Integration user config
  type: object
clickhouse_kafka:
  title: Integration user config
  type: object
  properties:
    tables:
      title: Tables to create
      type: array
      default: []
      items:
        title: Table to create
        type: object
        required:
          - name
          - columns
          - topics
          - data_format
          - group_name
        properties:
          auto_offset_reset:
            title: Action to take when there is no initial offset in offset store or the desired offset is out of range
            type: string
            default: earliest
            enum:
              - value: beginning
              - value: earliest
              - value: end
              - value: largest
              - value: latest
              - value: smallest
            example: latest
          columns:
            title: Table columns
            type: array
            items:
              title: Table column
              type: object
              required:
                - name
                - type
              properties:
                name:
                  title: Column name
                  type: string
                  min_length: 1
                  max_length: 40
                  example: key
                type:
                  title: Column type
                  type: string
                  min_length: 1
                  max_length: 1000
                  example: UInt64
            max_items: 100
          data_format:
            title: Message data format
            type: string
            default: JSONEachRow
            enum:
              - value: Avro
              - value: AvroConfluent
              - value: CSV
              - value: JSONAsString
              - value: JSONCompactEachRow
              - value: JSONCompactStringsEachRow
              - value: JSONEachRow
              - value: JSONStringsEachRow
              - value: MsgPack
              - value: Parquet
              - value: RawBLOB
              - value: TSKV
              - value: TSV
              - value: TabSeparated
            example: JSONEachRow
          date_time_input_format:
            title: Method to read DateTime from text input formats
            type: string
            default: basic
            enum:
              - value: basic
              - value: best_effort
              - value: best_effort_us
            example: best_effort
          group_name:
            title: Kafka consumers group
            type: string
            default: clickhouse
            min_length: 1
            max_length: 249
            example: clickhouse
          handle_error_mode:
            title: How to handle errors for Kafka engine
            type: string
            default: default
            enum:
              - value: default
              - value: stream
            example: stream
          max_block_size:
            title: Number of row collected by poll(s) for flushing data from Kafka
            type: integer
            default: "0"
            minimum: 0
            maximum: 1e+09
            example: "100000"
          max_rows_per_message:
            title: The maximum number of rows produced in one kafka message for row-based formats
            type: integer
            default: "1"
            minimum: 1
            maximum: 1e+09
            example: "100000"
          name:
            title: Name of the table
            type: string
            min_length: 1
            max_length: 40
            example: events
          num_consumers:
            title: The number of consumers per table per replica
            type: integer
            default: "1"
            minimum: 1
            maximum: 10
            example: "4"
          poll_max_batch_size:
            title: Maximum amount of messages to be polled in a single Kafka poll
            type: integer
            default: "0"
            minimum: 0
            maximum: 1e+09
            example: "10000"
          poll_max_timeout_ms:
            title: Timeout in milliseconds for a single poll from Kafka. Takes the value of the stream_flush_interval_ms server setting by default (500ms).
            type: integer
            default: "0"
            minimum: 0
            maximum: 30000
            example: "1000"
          skip_broken_messages:
            title: Skip at least this number of broken messages from Kafka topic per block
            type: integer
            default: "0"
            minimum: 0
            maximum: 1e+09
            example: "10000"
          thread_per_consumer:
            title: Provide an independent thread for each consumer. All consumers run in the same thread by default.
            type: boolean
            default: false
            example: true
          topics:
            title: Kafka topics
            type: array
            items:
              title: Kafka topic
              type: object
              required:
                - name
              properties:
                name:
                  title: Name of the topic
                  type: string
                  min_length: 1
                  max_length: 249
                  pattern: ^(?!\.$|\.\.$)[-_.A-Za-z0-9]+$
                  example: topic_name
                  user_error: Must consist of alpha-numeric characters, underscores, dashes or dots, max 249 characters
            max_items: 100
      max_items: 100
clickhouse_postgresql:
  title: Integration user config
  type: object
  properties:
    databases:
      title: Databases to expose
      type: array
      default:
        - database: defaultdb
          schema: public
      items:
        title: Database to expose
        type: object
        properties:
          database:
            title: PostgreSQL database to expose
            type: string
            default: defaultdb
            min_length: 1
            max_length: 63
            example: defaultdb
          schema:
            title: PostgreSQL schema to expose
            type: string
            default: public
            min_length: 1
            max_length: 63
            example: public
      max_items: 10
dashboard:
  title: Integration user config
  type: object
datadog:
  type: object
  properties:
    datadog_dbm_enabled:
      title: Enable Datadog Database Monitoring
      type: boolean
      example: true
    datadog_pgbouncer_enabled:
      title: Enable Datadog PgBouncer Metric Tracking
      type: boolean
      example: true
    datadog_tags:
      title: Custom tags provided by user
      type: array
      items:
        title: Datadog tag defined by user
        type: object
        required:
          - tag
        properties:
          comment:
            title: Optional tag explanation
            type: string
            max_length: 1024
            example: Used to tag primary replica metrics
          tag:
            title: Tag value
            description: 'Tag format and usage are described here: https://docs.datadoghq.com/getting_started/tagging. Tags with prefix ''aiven-'' are reserved for Aiven.'
            type: string
            min_length: 1
            max_length: 200
            pattern: ^(?!aiven-)[^\W\d_](?:[:\w./-]*[\w./-])?$
            example: replica:primary
            user_error: |
              Tags must start with a letter and after that may contain the characters listed below:
              alphanumerics, underscores, minuses, colons, periods, slashes.
              A tag cannot end with a colon.
              Tags can be up to 200 characters long and support Unicode.
              Tags with prefix 'aiven-' are reserved for Aiven.
              More info: https://docs.datadoghq.com/getting_started/tagging.
      max_items: 32
      example:
        - tag: foo
        - comment: Useful tag
          tag: bar:buzz
    exclude_consumer_groups:
      title: List of custom metrics
      type: array
      items:
        title: Consumer groups to exclude
        type: string
        max_length: 1024
        example: '[ group_a, group_b ]'
      max_items: 1024
    exclude_topics:
      title: List of topics to exclude
      type: array
      items:
        title: Topics to exclude
        type: string
        max_length: 1024
        example: '[ topic_x, topic_y ]'
      max_items: 1024
    include_consumer_groups:
      title: List of custom metrics
      type: array
      items:
        title: Consumer groups to include
        type: string
        max_length: 1024
        example: '[ group_a, group_b ]'
      max_items: 1024
    include_topics:
      title: List of topics to include
      type: array
      items:
        title: Topics to include
        type: string
        max_length: 1024
        example: '[ topic_x, topic_y ]'
      max_items: 1024
    kafka_custom_metrics:
      title: List of custom metrics
      type: array
      items:
        title: Metric name
        type: string
        enum:
          - value: kafka.log.log_end_offset
          - value: kafka.log.log_size
          - value: kafka.log.log_start_offset
        max_length: 1024
        example: kafka.log.log_size
      max_items: 1024
    max_jmx_metrics:
      title: Maximum number of JMX metrics to send
      type: integer
      minimum: 10
      maximum: 100000
      example: "2000"
    mirrormaker_custom_metrics:
      title: List of custom metrics
      type: array
      items:
        title: Metric name
        type: string
        enum:
          - value: kafka_mirrormaker_summary.replication_lag
        max_length: 1024
        example: kafka_mirrormaker_summary.replication_lag
      max_items: 1024
    opensearch:
      title: Datadog Opensearch Options
      type: object
      properties:
        cluster_stats_enabled:
          title: Enable Datadog Opensearch Cluster Monitoring
          type: boolean
          example: true
        index_stats_enabled:
          title: Enable Datadog Opensearch Index Monitoring
          type: boolean
          example: true
        pending_task_stats_enabled:
          title: Enable Datadog Opensearch Pending Task Monitoring
          type: boolean
          example: true
        pshard_stats_enabled:
          title: Enable Datadog Opensearch Primary Shard Monitoring
          type: boolean
          example: true
    redis:
      title: Datadog Redis Options
      type: object
      properties:
        command_stats_enabled:
          title: Redis command statistics for Datadog integrations
          description: Enable command_stats option in the agent's configuration
          type: boolean
          default: false
datasource:
  title: Integration user config
  type: object
external_aws_cloudwatch_logs:
  title: Integration user config
  type: object
  properties:
    selected_log_fields:
      title: List of logging fields to include
      description: The list of logging fields that will be sent to the integration logging service. The MESSAGE and timestamp fields are always sent.
      type: array
      items:
        title: Log field name
        type: string
        enum:
          - value: HOSTNAME
          - value: PRIORITY
          - value: REALTIME_TIMESTAMP
          - value: SYSTEMD_UNIT
          - value: service_name
      max_items: 5
external_aws_cloudwatch_metrics:
  title: External AWS CloudWatch Metrics integration user config
  type: object
  properties:
    dropped_metrics:
      title: Metrics to not send to AWS CloudWatch (takes precedence over extra_metrics)
      type: array
      items:
        title: Metric name and subfield
        type: object
        required:
          - metric
          - field
        properties:
          field:
            title: Identifier of a value in the metric
            type: string
            max_length: 1000
            example: used
          metric:
            title: Identifier of the metric
            type: string
            max_length: 1000
            example: java.lang:Memory
      max_items: 1024
      example:
        - field: evicted_keys
          metric: redis
    extra_metrics:
      title: Metrics to allow through to AWS CloudWatch (in addition to default metrics)
      type: array
      items:
        title: Metric name and subfield
        type: object
        required:
          - metric
          - field
        properties:
          field:
            title: Identifier of a value in the metric
            type: string
            max_length: 1000
            example: used
          metric:
            title: Identifier of the metric
            type: string
            max_length: 1000
            example: java.lang:Memory
      max_items: 1024
      example:
        - field: evicted_keys
          metric: redis
external_elasticsearch_logs:
  title: Integration user config
  type: object
  properties:
    selected_log_fields:
      title: List of logging fields to include
      description: The list of logging fields that will be sent to the integration logging service. The MESSAGE and timestamp fields are always sent.
      type: array
      items:
        title: Log field name
        type: string
        enum:
          - value: HOSTNAME
          - value: PRIORITY
          - value: REALTIME_TIMESTAMP
          - value: SYSTEMD_UNIT
          - value: service_name
      max_items: 5
external_google_cloud_logging:
  title: Integration user config
  type: object
external_opensearch_logs:
  title: Integration user config
  type: object
  properties:
    selected_log_fields:
      title: List of logging fields to include
      description: The list of logging fields that will be sent to the integration logging service. The MESSAGE and timestamp fields are always sent.
      type: array
      items:
        title: Log field name
        type: string
        enum:
          - value: HOSTNAME
          - value: PRIORITY
          - value: REALTIME_TIMESTAMP
          - value: SYSTEMD_UNIT
          - value: service_name
      max_items: 5
flink:
  title: Integration user config
  type: object
flink_external_bigquery:
  title: Integration user config
  type: object
flink_external_kafka:
  title: Integration user config
  type: object
flink_external_postgresql:
  title: Integration user config
  type: object
  properties:
    stringtype:
      title: The parameter stringtype in the JDBC URL
      description: If stringtype is set to unspecified, parameters will be sent to the server as untyped values
      type: string
      enum:
        - value: unspecified
      example: unspecified
jolokia:
  title: Integration user config
  type: object
kafka_connect:
  title: Integration user config
  type: object
  properties:
    kafka_connect:
      title: Kafka Connect service configuration values
      type: object
      properties:
        config_storage_topic:
          title: The name of the topic where connector and task configuration data are stored.This must be the same for all workers with the same group_id.
          type: string
          max_length: 249
          example: __connect_configs
        group_id:
          title: A unique string that identifies the Connect cluster group this worker belongs to.
          type: string
          max_length: 249
          example: connect
        offset_storage_topic:
          title: The name of the topic where connector and task configuration offsets are stored.This must be the same for all workers with the same group_id.
          type: string
          max_length: 249
          example: __connect_offsets
        status_storage_topic:
          title: The name of the topic where connector and task configuration status updates are stored.This must be the same for all workers with the same group_id.
          type: string
          max_length: 249
          example: __connect_status
kafka_logs:
  type: object
  required:
    - kafka_topic
  properties:
    kafka_topic:
      title: Topic name
      type: string
      min_length: 1
      max_length: 249
      pattern: ^(?!\.$|\.\.$)[-_.A-Za-z0-9]+$
      example: mytopic
      user_error: Must consist of alpha-numeric characters, underscores, dashes or dots, max 249 characters
    selected_log_fields:
      title: List of logging fields to include
      description: The list of logging fields that will be sent to the integration logging service. The MESSAGE and timestamp fields are always sent.
      type: array
      items:
        title: Log field name
        type: string
        enum:
          - value: HOSTNAME
          - value: PRIORITY
          - value: REALTIME_TIMESTAMP
          - value: SYSTEMD_UNIT
          - value: service_name
      max_items: 5
kafka_mirrormaker:
  title: Integration user config
  type: object
  properties:
    cluster_alias:
      title: Kafka cluster alias
      description: 'The alias under which the Kafka cluster is known to MirrorMaker. Can contain the following symbols: ASCII alphanumerics, ''.'', ''_'', and ''-''.'
      type: string
      max_length: 128
      pattern: ^[a-zA-Z0-9_.-]+$
      example: kafka-abc
      user_error: Must consist of alpha-numeric ASCII characters, dashes, underscores, and dots, max 128 characters.
    kafka_mirrormaker:
      title: Kafka MirrorMaker configuration values
      type: object
      properties:
        consumer_auto_offset_reset:
          title: Set the auto.offset.reset to consumer.
          description: 'Set where consumer starts to consume data. Value `earliest`: Start replication from the earliest offset. Value `latest`: Start replication from the latest offset. Default is `earliest`.'
          type:
            - string
            - "null"
          enum:
            - value: earliest
            - value: latest
        consumer_fetch_min_bytes:
          title: consumer.fetch.min.bytes
          description: The minimum amount of data the server should return for a fetch request
          type: integer
          minimum: 1
          maximum: 5.24288e+06
          example: "1024"
        consumer_max_poll_records:
          title: Set the max.poll.records to consumer.
          description: Set consumer max.poll.records. The default is 500.
          type:
            - integer
            - "null"
          minimum: 100
          maximum: 20000
          example: "500"
        producer_batch_size:
          title: producer.batch.size
          description: The batch size in bytes producer will attempt to collect before publishing to broker.
          type: integer
          minimum: 0
          maximum: 5.24288e+06
          example: "1024"
        producer_buffer_memory:
          title: producer.buffer.memory
          description: The amount of bytes producer can use for buffering data before publishing to broker.
          type: integer
          minimum: 5.24288e+06
          maximum: 1.34217728e+08
          example: "8388608"
        producer_compression_type:
          title: producer.compression.type
          description: Specify the default compression type for producers. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'none' which is the default and equivalent to no compression.
          type: string
          enum:
            - value: gzip
            - value: lz4
            - value: none
            - value: snappy
            - value: zstd
        producer_linger_ms:
          title: producer.linger.ms
          description: The linger time (ms) for waiting new data to arrive for publishing.
          type: integer
          minimum: 0
          maximum: 5000
          example: "100"
        producer_max_request_size:
          title: producer.max.request.size
          description: The maximum request size in bytes.
          type: integer
          minimum: 0
          maximum: 2.68435456e+08
          example: "1048576"
logs:
  type: object
  properties:
    elasticsearch_index_days_max:
      title: Elasticsearch index retention limit
      type: integer
      default: "3"
      minimum: 1
      maximum: 10000
      example: "5"
    elasticsearch_index_prefix:
      title: Elasticsearch index prefix
      type: string
      default: logs
      min_length: 1
      max_length: 1024
      example: logs
    selected_log_fields:
      title: List of logging fields to include
      description: The list of logging fields that will be sent to the integration logging service. The MESSAGE and timestamp fields are always sent.
      type: array
      items:
        title: Log field name
        type: string
        enum:
          - value: HOSTNAME
          - value: PRIORITY
          - value: REALTIME_TIMESTAMP
          - value: SYSTEMD_UNIT
          - value: service_name
      max_items: 5
m3aggregator:
  title: Integration user config
  type: object
m3coordinator:
  is_deprecated: true
  deprecation_notice: This property is deprecated.
  title: Integration user config
  type: object
metrics:
  title: Integration user config
  type: object
  properties:
    database:
      title: Name of the database where to store metric datapoints. Only affects PostgreSQL destinations. Defaults to 'metrics'. Note that this must be the same for all metrics integrations that write data to the same PostgreSQL service.
      type: string
      max_length: 40
      pattern: ^[_A-Za-z0-9][-_A-Za-z0-9]{0,39}$
      example: metrics
      user_error: Must consist of alpha-numeric characters, underscores or dashes, may not start with dash, max 40 characters
    retention_days:
      title: Number of days to keep old metrics. Only affects PostgreSQL destinations. Set to 0 for no automatic cleanup. Defaults to 30 days.
      type: integer
      minimum: 0
      maximum: 10000
      example: "30"
    ro_username:
      title: Name of a user that can be used to read metrics. This will be used for Grafana integration (if enabled) to prevent Grafana users from making undesired changes. Only affects PostgreSQL destinations. Defaults to 'metrics_reader'. Note that this must be the same for all metrics integrations that write data to the same PostgreSQL service.
      type: string
      max_length: 40
      pattern: ^[_A-Za-z0-9][-._A-Za-z0-9]{0,39}$
      example: metrics_reader
      user_error: Must consist of alpha-numeric characters, dots, underscores or dashes, may not start with dash or dot, max 40 characters
    source_mysql:
      title: Configuration options for metrics where source service is MySQL
      type: object
      properties:
        telegraf:
          title: Configuration options for Telegraf MySQL input plugin
          type: object
          properties:
            gather_event_waits:
              title: Gather metrics from PERFORMANCE_SCHEMA.EVENT_WAITS
              type: boolean
              example: false
            gather_file_events_stats:
              title: gather metrics from PERFORMANCE_SCHEMA.FILE_SUMMARY_BY_EVENT_NAME
              type: boolean
              example: false
            gather_index_io_waits:
              title: Gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE
              type: boolean
              example: false
            gather_info_schema_auto_inc:
              title: Gather auto_increment columns and max values from information schema
              type: boolean
              example: false
            gather_innodb_metrics:
              title: Gather metrics from INFORMATION_SCHEMA.INNODB_METRICS
              type: boolean
              example: true
            gather_perf_events_statements:
              title: Gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_DIGEST
              type: boolean
              example: false
            gather_process_list:
              title: Gather thread state counts from INFORMATION_SCHEMA.PROCESSLIST
              type: boolean
              example: true
            gather_slave_status:
              title: Gather metrics from SHOW SLAVE STATUS command output
              type: boolean
              example: true
            gather_table_io_waits:
              title: Gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_TABLE
              type: boolean
              example: false
            gather_table_lock_waits:
              title: Gather metrics from PERFORMANCE_SCHEMA.TABLE_LOCK_WAITS
              type: boolean
              example: false
            gather_table_schema:
              title: Gather metrics from INFORMATION_SCHEMA.TABLES
              type: boolean
              example: true
            perf_events_statements_digest_text_limit:
              title: Truncates digest text from perf_events_statements into this many characters
              type: integer
              minimum: 1
              maximum: 2048
              example: "120"
            perf_events_statements_limit:
              title: Limits metrics from perf_events_statements
              type: integer
              minimum: 1
              maximum: 4000
              example: "250"
            perf_events_statements_time_limit:
              title: Only include perf_events_statements whose last seen is less than this many seconds
              type: integer
              minimum: 1
              maximum: 2.592e+06
              example: "86400"
    username:
      title: Name of the user used to write metrics. Only affects PostgreSQL destinations. Defaults to 'metrics_writer'. Note that this must be the same for all metrics integrations that write data to the same PostgreSQL service.
      type: string
      max_length: 40
      pattern: ^[_A-Za-z0-9][-._A-Za-z0-9]{0,39}$
      example: metrics_writer
      user_error: Must consist of alpha-numeric characters, dots, underscores or dashes, may not start with dash or dot, max 40 characters
prometheus:
  title: Integration user config
  type: object
  properties:
    source_mysql:
      title: Configuration options for metrics where source service is MySQL
      type: object
      properties:
        telegraf:
          title: Configuration options for Telegraf MySQL input plugin
          type: object
          properties:
            gather_event_waits:
              title: Gather metrics from PERFORMANCE_SCHEMA.EVENT_WAITS
              type: boolean
              example: false
            gather_file_events_stats:
              title: gather metrics from PERFORMANCE_SCHEMA.FILE_SUMMARY_BY_EVENT_NAME
              type: boolean
              example: false
            gather_index_io_waits:
              title: Gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE
              type: boolean
              example: false
            gather_info_schema_auto_inc:
              title: Gather auto_increment columns and max values from information schema
              type: boolean
              example: false
            gather_innodb_metrics:
              title: Gather metrics from INFORMATION_SCHEMA.INNODB_METRICS
              type: boolean
              example: true
            gather_perf_events_statements:
              title: Gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_DIGEST
              type: boolean
              example: false
            gather_process_list:
              title: Gather thread state counts from INFORMATION_SCHEMA.PROCESSLIST
              type: boolean
              example: true
            gather_slave_status:
              title: Gather metrics from SHOW SLAVE STATUS command output
              type: boolean
              example: true
            gather_table_io_waits:
              title: Gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_TABLE
              type: boolean
              example: false
            gather_table_lock_waits:
              title: Gather metrics from PERFORMANCE_SCHEMA.TABLE_LOCK_WAITS
              type: boolean
              example: false
            gather_table_schema:
              title: Gather metrics from INFORMATION_SCHEMA.TABLES
              type: boolean
              example: true
            perf_events_statements_digest_text_limit:
              title: Truncates digest text from perf_events_statements into this many characters
              type: integer
              minimum: 1
              maximum: 2048
              example: "120"
            perf_events_statements_limit:
              title: Limits metrics from perf_events_statements
              type: integer
              minimum: 1
              maximum: 4000
              example: "250"
            perf_events_statements_time_limit:
              title: Only include perf_events_statements whose last seen is less than this many seconds
              type: integer
              minimum: 1
              maximum: 2.592e+06
              example: "86400"
rsyslog:
  title: Integration user config
  type: object
thanos_migrate:
  title: Integration user config
  type: object
